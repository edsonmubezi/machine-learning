{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction in Tanzania\n",
    "### Machine Learning Project\n",
    "\n",
    "**Objective:** Predict crop yield (kg per acre) for Tanzanian farmers using Linear Regression and Decision Tree models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('crop_data.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print('First 5 rows of the dataset:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "print(f'Dataset has {df.shape[0]} rows and {df.shape[1]} columns')\n",
    "print()\n",
    "\n",
    "# Data types\n",
    "print('Data types:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Missing values in each column:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean of each column\n",
    "df['rainfall_mm'] = df['rainfall_mm'].fillna(df['rainfall_mm'].mean())\n",
    "df['temperature_c'] = df['temperature_c'].fillna(df['temperature_c'].mean())\n",
    "df['fertilizer_kg'] = df['fertilizer_kg'].fillna(df['fertilizer_kg'].mean())\n",
    "\n",
    "# Verify no more missing values\n",
    "print('Missing values after cleaning:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns using LabelEncoder\n",
    "label_encoders = {}\n",
    "\n",
    "categorical_columns = ['region', 'crop_type', 'soil_type']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f'{col}: {list(le.classes_)}')\n",
    "\n",
    "print()\n",
    "print('Data after encoding:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop('yield_kg_per_acre', axis=1)\n",
    "y = df['yield_kg_per_acre']\n",
    "\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training set: {X_train.shape[0]} samples')\n",
    "print(f'Testing set: {X_test.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "print('Linear Regression model trained successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree model\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "print('Decision Tree model trained successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Linear Regression\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "dt_mae = mean_absolute_error(y_test, dt_predictions)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "\n",
    "# Display results\n",
    "print('='*50)\n",
    "print('MODEL COMPARISON RESULTS')\n",
    "print('='*50)\n",
    "print(f'\\nLinear Regression:')\n",
    "print(f'  MAE  = {lr_mae:.2f} kg/acre')\n",
    "print(f'  R2   = {lr_r2:.4f}')\n",
    "print(f'\\nDecision Tree:')\n",
    "print(f'  MAE  = {dt_mae:.2f} kg/acre')\n",
    "print(f'  R2   = {dt_r2:.4f}')\n",
    "print()\n",
    "\n",
    "# Determine the best model\n",
    "if lr_r2 > dt_r2:\n",
    "    print('>>> Linear Regression is the BETTER model!')\n",
    "    best_model = lr_model\n",
    "    best_name = 'Linear Regression'\n",
    "else:\n",
    "    print('>>> Decision Tree is the BETTER model!')\n",
    "    best_model = dt_model\n",
    "    best_name = 'Decision Tree'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 1: Model Comparison - R2 Score and MAE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# R2 Score comparison\n",
    "models = ['Linear Regression', 'Decision Tree']\n",
    "r2_scores = [lr_r2, dt_r2]\n",
    "colors = ['#3498db', '#2ecc71']\n",
    "\n",
    "axes[0].bar(models, r2_scores, color=colors)\n",
    "axes[0].set_title('R2 Score Comparison')\n",
    "axes[0].set_ylabel('R2 Score')\n",
    "for i, v in enumerate(r2_scores):\n",
    "    axes[0].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# MAE comparison\n",
    "mae_scores = [lr_mae, dt_mae]\n",
    "axes[1].bar(models, mae_scores, color=colors)\n",
    "axes[1].set_title('MAE Comparison (lower is better)')\n",
    "axes[1].set_ylabel('Mean Absolute Error')\n",
    "for i, v in enumerate(mae_scores):\n",
    "    axes[1].text(i, v + 2, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 2: Actual vs Predicted values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].scatter(y_test, lr_predictions, alpha=0.5, color='#3498db')\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[0].set_xlabel('Actual Yield')\n",
    "axes[0].set_ylabel('Predicted Yield')\n",
    "axes[0].set_title('Linear Regression: Actual vs Predicted')\n",
    "\n",
    "axes[1].scatter(y_test, dt_predictions, alpha=0.5, color='#2ecc71')\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[1].set_xlabel('Actual Yield')\n",
    "axes[1].set_ylabel('Predicted Yield')\n",
    "axes[1].set_title('Decision Tree: Actual vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('actual_vs_predicted.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 3: Feature Importance from Decision Tree\n",
    "feature_names = X.columns\n",
    "importances = dt_model.feature_importances_\n",
    "\n",
    "# Sort by importance\n",
    "sorted_idx = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(sorted_idx)), importances[sorted_idx], color='#e74c3c')\n",
    "plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Decision Tree - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 4: Distribution of Crop Yield\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['yield_kg_per_acre'], bins=30, color='#9b59b6', edgecolor='black')\n",
    "plt.xlabel('Yield (kg per acre)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Crop Yield')\n",
    "plt.tight_layout()\n",
    "plt.savefig('yield_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save the label encoders (needed for the app)\n",
    "with open('encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "print(f'Best model ({best_name}) saved as model.pkl')\n",
    "print('Label encoders saved as encoders.pkl')\n",
    "print('\\nProject complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
